{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/raghavsharma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/raghavsharma/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/raghavsharma/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.translate import bleu\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from heapq import nlargest\n",
    "\n",
    "import openai\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>comment</th>\n",
       "      <th>event</th>\n",
       "      <th>event_player</th>\n",
       "      <th>event_team</th>\n",
       "      <th>comment_desc</th>\n",
       "      <th>home_team</th>\n",
       "      <th>home_team_abbr</th>\n",
       "      <th>away_team</th>\n",
       "      <th>away_team_abbr</th>\n",
       "      <th>full_time_score</th>\n",
       "      <th>match</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>match_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>thanks for joining our commentary this evenin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full time summary</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>BAR</td>\n",
       "      <td>bayern munchen</td>\n",
       "      <td>FCB</td>\n",
       "      <td>0 - 3</td>\n",
       "      <td>Barcelona vs Bayern Muenchen</td>\n",
       "      <td>09/14/21</td>\n",
       "      <td>https://www.goal.com/en/match/barcelona-vs-bay...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>barcelona are next in action at home in lalig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full time summary</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>BAR</td>\n",
       "      <td>bayern munchen</td>\n",
       "      <td>FCB</td>\n",
       "      <td>0 - 3</td>\n",
       "      <td>Barcelona vs Bayern Muenchen</td>\n",
       "      <td>09/14/21</td>\n",
       "      <td>https://www.goal.com/en/match/barcelona-vs-bay...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bayern munich have eased past barcelona in th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full time summary</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>BAR</td>\n",
       "      <td>bayern munchen</td>\n",
       "      <td>FCB</td>\n",
       "      <td>0 - 3</td>\n",
       "      <td>Barcelona vs Bayern Muenchen</td>\n",
       "      <td>09/14/21</td>\n",
       "      <td>https://www.goal.com/en/match/barcelona-vs-bay...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90 + 2</td>\n",
       "      <td>full-time: barcelona 0-3 bayern munich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timer</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>BAR</td>\n",
       "      <td>bayern munchen</td>\n",
       "      <td>FCB</td>\n",
       "      <td>0 - 3</td>\n",
       "      <td>Barcelona vs Bayern Muenchen</td>\n",
       "      <td>09/14/21</td>\n",
       "      <td>https://www.goal.com/en/match/barcelona-vs-bay...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>there will be two minutes of added time.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timer</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>BAR</td>\n",
       "      <td>bayern munchen</td>\n",
       "      <td>FCB</td>\n",
       "      <td>0 - 3</td>\n",
       "      <td>Barcelona vs Bayern Muenchen</td>\n",
       "      <td>09/14/21</td>\n",
       "      <td>https://www.goal.com/en/match/barcelona-vs-bay...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time                                            comment event  \\\n",
       "0     NaN   thanks for joining our commentary this evenin...   NaN   \n",
       "1     NaN   barcelona are next in action at home in lalig...   NaN   \n",
       "2     NaN   bayern munich have eased past barcelona in th...   NaN   \n",
       "3  90 + 2            full-time: barcelona 0-3 bayern munich    NaN   \n",
       "4      90          there will be two minutes of added time.    NaN   \n",
       "\n",
       "  event_player event_team       comment_desc  home_team home_team_abbr  \\\n",
       "0          NaN        NaN  full time summary  barcelona            BAR   \n",
       "1          NaN        NaN  full time summary  barcelona            BAR   \n",
       "2          NaN        NaN  full time summary  barcelona            BAR   \n",
       "3          NaN        NaN              timer  barcelona            BAR   \n",
       "4          NaN        NaN              timer  barcelona            BAR   \n",
       "\n",
       "        away_team away_team_abbr full_time_score  \\\n",
       "0  bayern munchen            FCB           0 - 3   \n",
       "1  bayern munchen            FCB           0 - 3   \n",
       "2  bayern munchen            FCB           0 - 3   \n",
       "3  bayern munchen            FCB           0 - 3   \n",
       "4  bayern munchen            FCB           0 - 3   \n",
       "\n",
       "                          match      date  \\\n",
       "0  Barcelona vs Bayern Muenchen  09/14/21   \n",
       "1  Barcelona vs Bayern Muenchen  09/14/21   \n",
       "2  Barcelona vs Bayern Muenchen  09/14/21   \n",
       "3  Barcelona vs Bayern Muenchen  09/14/21   \n",
       "4  Barcelona vs Bayern Muenchen  09/14/21   \n",
       "\n",
       "                                                link  match_id  \n",
       "0  https://www.goal.com/en/match/barcelona-vs-bay...         0  \n",
       "1  https://www.goal.com/en/match/barcelona-vs-bay...         0  \n",
       "2  https://www.goal.com/en/match/barcelona-vs-bay...         0  \n",
       "3  https://www.goal.com/en/match/barcelona-vs-bay...         0  \n",
       "4  https://www.goal.com/en/match/barcelona-vs-bay...         0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_df = pd.read_csv('../../data/commentory_matchid.csv')\n",
    "comm_df = comm_df[comm_df['match_id'] != 95]\n",
    "comm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use sliding window technique with 15 mins buffer for the match live ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_df(df, start_timer, end_timer):\n",
    "    # Convert time column to str\n",
    "    df['time'] = df['time'].astype(str)\n",
    "    comments = []\n",
    "    for i in range(df.shape[0]):\n",
    "        time = df['time'][i]\n",
    "        if time != 'nan':\n",
    "            if '+' in time:\n",
    "                time = time[:2]\n",
    "            if int(time) >= start_timer and int(time) < end_timer:\n",
    "                if df['comment_desc'][i] == 'timer':\n",
    "                    comments.append(df['comment'][i])\n",
    "    return \" \".join(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(df):\n",
    "    all_comm = []\n",
    "    match_ids = df['match_id'].unique()\n",
    "    for id in match_ids:\n",
    "        # Filter the dataframe w.r.t match_id\n",
    "        match_df = df[df['match_id'] == id]\n",
    "        match_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        # Divide the dataframe into 6 separate dfs, each corresponding to 15 minutes of the match.\n",
    "        comm_15 = window_df(match_df, 0, 16)\n",
    "        comm_30 = window_df(match_df, 16, 31)\n",
    "        comm_45 = window_df(match_df, 31, 46)\n",
    "        comm_60 = window_df(match_df, 46, 61)\n",
    "        comm_75 = window_df(match_df, 61, 76)\n",
    "        comm_90 = window_df(match_df, 76, 91)\n",
    "\n",
    "        # Append the respective live tickers to a list\n",
    "        all_comm.append([comm_15, comm_30, comm_45, comm_60, comm_75, comm_90])\n",
    "    \n",
    "    return all_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentaries = create_window(comm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be used later for summaries\n",
    "timer_list= ['[1-15]', '[16-30]', '[31-45]', '[46-60]', '[61-75]', '[76-90]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SpaCy to summarize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_spacy_summary(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    keyword = []\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']\n",
    "    for token in doc:\n",
    "        if (token.text in stopwords or token.text in punctuation):\n",
    "            continue\n",
    "        if token.pos_ in pos_tag:\n",
    "            keyword.append(token.text)\n",
    "\n",
    "    freq_word = Counter(keyword)\n",
    "    max_freq = Counter(keyword).most_common(1)[0][1]\n",
    "    for word in freq_word.keys():\n",
    "        freq_word[word] = (freq_word[word]/max_freq)\n",
    "\n",
    "    sent_strenght = {}\n",
    "    for sent in doc.sents:\n",
    "        for word in sent:\n",
    "            if word.text in freq_word.keys():\n",
    "                if sent in sent_strenght.keys():\n",
    "                    sent_strenght[sent] += freq_word[word.text]\n",
    "                else:\n",
    "                    sent_strenght[sent] = freq_word[word.text]\n",
    "\n",
    "    summarized_sentences = nlargest(3, sent_strenght, key=sent_strenght.get)\n",
    "    final_sentences = [w.text for w in summarized_sentences]\n",
    "    return \" \".join(final_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_comm_spacy(comms):\n",
    "    all_comm_spacy = []\n",
    "    for commentary in comms:\n",
    "        spacy_window_comm = []\n",
    "        for comment in commentary:\n",
    "            spacy_window_comm.append(get_spacy_summary(comment))\n",
    "        all_comm_spacy.append(\" \".join(spacy_window_comm))\n",
    "    return all_comm_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_comm = get_all_comm_spacy(commentaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLTK for text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    \"\"\" A method to remove punctuations from text \"\"\"\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text) #removes numbers from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    \"\"\" A method to tokenize text data \"\"\"\n",
    "    text = re.split('\\W+', text) #splitting each sentence/ tweet into its individual words\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_nltk(text, num_sentences=3):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Tokenize the sentences into words and remove stopwords\n",
    "    \n",
    "    text_punct_removed = remove_punct(text)\n",
    "    words = tokenization(text_punct_removed.lower())\n",
    "    \n",
    "    # words = word_tokenize(text)\n",
    "\n",
    "    # remove stopwords\n",
    "    stop_words =  set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Apply stemming to the filtered words\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "    # Lemmatize words\n",
    "    word_net_lemma = nltk.WordNetLemmatizer()\n",
    "    word_lemma = [word_net_lemma.lemmatize(word) for word in stemmed_words]\n",
    "    \n",
    "    # Calculate word frequency and sentence scores\n",
    "    word_freq = nltk.FreqDist(stemmed_words)\n",
    "    sentence_scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in nltk.word_tokenize(sentence.lower()):\n",
    "            if word in word_freq:\n",
    "                if len(sentence.split()) < 30:\n",
    "                    if i not in sentence_scores:\n",
    "                        sentence_scores[i] = word_freq[word]\n",
    "                    else:\n",
    "                        sentence_scores[i] += word_freq[word]\n",
    "    \n",
    "    # Select the top sentences based on their scores\n",
    "    summary_sentences = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    summary = [sentences[i] for i in sorted(summary_sentences)]\n",
    "    return \" \".join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_comm_nltk(comms):\n",
    "    all_comm_nltk = []\n",
    "    for commentary in comms:\n",
    "        nltk_window_comm = []\n",
    "        for comment in commentary:\n",
    "            nltk_window_comm.append(summarize_text_nltk(comment))\n",
    "        all_comm_nltk.append(\" \".join(nltk_window_comm))\n",
    "    return all_comm_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_comm = get_all_comm_nltk(commentaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_gpt(corpus, org_key, api_key):\n",
    "    openai.organization = org_key\n",
    "    openai.api_key = api_key\n",
    "    engine_list = openai.Engine.list() # calling the engines available from the openai api \n",
    "\n",
    "    response = openai.Completion.create(engine=\"davinci\",prompt=corpus,temperature=0.3,\n",
    "            max_tokens=200,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=[\"\\n\"]\n",
    "        )\n",
    "    return response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_comm_gpt(comms, org_key, api_key):\n",
    "    all_comm_gpt = []\n",
    "    for commentary in comms:\n",
    "        gpt_window_comm = []\n",
    "        for comment in commentary:\n",
    "            gpt_window_comm.append(summarize_text_gpt(comment, org_key, api_key))\n",
    "        all_comm_gpt.append(\" \".join(gpt_window_comm))\n",
    "    return all_comm_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading keys from file\n",
    "\n",
    "api = pd.read_csv('../../../OpenAI.txt')\n",
    "\n",
    "api_key = api[\"Key\"][0]\n",
    "org_key = api[\"Key\"][1]\n",
    "gpt_comm = get_all_comm_gpt(commentaries, org_key, api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get full time summary from comment description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_match_summ(df):\n",
    "    all_ft_comm = []\n",
    "    match_ids = df['match_id'].unique()\n",
    "    for id in match_ids:\n",
    "        # Filter the dataframe w.r.t match_id\n",
    "        match_df = df[df['match_id'] == id]\n",
    "        all_ft_comm.append(\" \".join(match_df[match_df['comment_desc'] == 'full time summary']['comment']))\n",
    "    \n",
    "    return all_ft_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ft_comm = get_full_match_summ(comm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BLEU score for checking similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_bleu(ft_summary, my_summary):\n",
    "#     return bleu([ft_summary.split()], my_summary.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using cosine-similarity for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CountVectorizer()\n",
    "def calc_cos_sim_count_vec(ft_summary, my_summary):\n",
    "    corpus = [ft_summary, my_summary]\n",
    "    # Create the Document Term Matrix\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    sparse_matrix = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, \n",
    "                    columns=count_vectorizer.vocabulary_.keys(), \n",
    "                    index=['ft_summary_org','ft_summary_crtd'])\n",
    "    \n",
    "    # Compute Cosine Similarity\n",
    "    return cosine_similarity(df[0:1], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using TF-IDF\n",
    "# def calc_cos_sim_tfidf(ft_summary, my_summary):\n",
    "#     corpus = [ft_summary, my_summary]\n",
    "#     vectorizer = TfidfVectorizer()\n",
    "#     trsfm=vectorizer.fit_transform(corpus)\n",
    "\n",
    "#     # OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "#     doc_term_matrix = trsfm.todense()\n",
    "#     trsfm_df = pd.DataFrame(doc_term_matrix,\n",
    "#                             columns=vectorizer.vocabulary_.keys(),\n",
    "#                             index=['ft_summary_org','ft_summary_crtd'])\n",
    "\n",
    "#     return cosine_similarity(trsfm[0:1], trsfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8232871328363739,\n",
       " 0.8174248588298362,\n",
       " 0.8145149399112754,\n",
       " 0.7816383863403364,\n",
       " 0.7707412659871002,\n",
       " 0.7694462678570619,\n",
       " 0.7659244889204044,\n",
       " 0.7649044889725534,\n",
       " 0.7634486278999365,\n",
       " 0.7582895374148945,\n",
       " 0.7518359657137371,\n",
       " 0.7472140658882348,\n",
       " 0.7429968507127381,\n",
       " 0.7387260114298334,\n",
       " 0.7347287011121258,\n",
       " 0.7334503928271484,\n",
       " 0.7310951615491647,\n",
       " 0.7299371348265824,\n",
       " 0.7296285367600028,\n",
       " 0.7280359685613873,\n",
       " 0.7261173975565213,\n",
       " 0.7229427592932066,\n",
       " 0.7208075167278749,\n",
       " 0.7200696963190241,\n",
       " 0.7195155789335859,\n",
       " 0.7192314578474367,\n",
       " 0.7184730379535103,\n",
       " 0.7176907877381489,\n",
       " 0.7174915295770368,\n",
       " 0.7168908512875278,\n",
       " 0.7164631047340766,\n",
       " 0.7130990002287594,\n",
       " 0.708139866273981,\n",
       " 0.7077639126053901,\n",
       " 0.7061962925226118,\n",
       " 0.7060672642464483,\n",
       " 0.7041160601434504,\n",
       " 0.7036982541979113,\n",
       " 0.7008160444039738,\n",
       " 0.6982421515857751,\n",
       " 0.6980133197158735,\n",
       " 0.6949830538115703,\n",
       " 0.6935688420806261,\n",
       " 0.6921769122637016,\n",
       " 0.6906989123143691,\n",
       " 0.6892093880551476,\n",
       " 0.6889921695571921,\n",
       " 0.6883405421257713,\n",
       " 0.6879942667838247,\n",
       " 0.6868483889289401,\n",
       " 0.6835664457752966,\n",
       " 0.6832065038732276,\n",
       " 0.6829922865086132,\n",
       " 0.6819611252611292,\n",
       " 0.6805031790794247,\n",
       " 0.6766716268549505,\n",
       " 0.6717400156643347,\n",
       " 0.6708100867927611,\n",
       " 0.6693243369233554,\n",
       " 0.6690256865044233,\n",
       " 0.6660644431623071,\n",
       " 0.6594341471305851,\n",
       " 0.6576805346959342,\n",
       " 0.6573471115796055,\n",
       " 0.6557803514914415,\n",
       " 0.6556759826906474,\n",
       " 0.6549326340760143,\n",
       " 0.6543313569495764,\n",
       " 0.6543056962702852,\n",
       " 0.6540244778196856,\n",
       " 0.6540152751647956,\n",
       " 0.6530001103217988,\n",
       " 0.6525493651938583,\n",
       " 0.6519753543978196,\n",
       " 0.6518337229135797,\n",
       " 0.6514441570730529,\n",
       " 0.6514258098447994,\n",
       " 0.6501686521203943,\n",
       " 0.6493769297175866,\n",
       " 0.6489514899722502,\n",
       " 0.6474095516631521,\n",
       " 0.6441428463760897,\n",
       " 0.6408601508588174,\n",
       " 0.640565709619598,\n",
       " 0.6404492823548781,\n",
       " 0.6377413519379004,\n",
       " 0.637482000956312,\n",
       " 0.6333670384229725,\n",
       " 0.6322346082101858,\n",
       " 0.6308462001233082,\n",
       " 0.6304214197561248,\n",
       " 0.629072431212435,\n",
       " 0.6282635844881552,\n",
       " 0.6267586708334285,\n",
       " 0.6262091442679684,\n",
       " 0.6255964734501984,\n",
       " 0.6240343769458064,\n",
       " 0.6238932167692193,\n",
       " 0.6217996822681201,\n",
       " 0.6195226999012896,\n",
       " 0.6153285660540193,\n",
       " 0.6131729173680263,\n",
       " 0.6095039829251624,\n",
       " 0.6090890782532357,\n",
       " 0.6032688902918693,\n",
       " 0.6031262308176589,\n",
       " 0.5959558305615295,\n",
       " 0.5924874589077336,\n",
       " 0.5897908270415203,\n",
       " 0.5877020374636478,\n",
       " 0.5835854479274057,\n",
       " 0.5830168805994301,\n",
       " 0.5816054590044272,\n",
       " 0.5797597937373427,\n",
       " 0.5780357550578806,\n",
       " 0.570635731378937,\n",
       " 0.5675697834024516,\n",
       " 0.5444999941290627,\n",
       " 0.5234661337433846,\n",
       " 0.5171983489492075,\n",
       " 0.5058344627239775,\n",
       " 0.5033785560432509,\n",
       " 0.4922973171086581,\n",
       " 0.45755805769973906]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cos_sim_spacy = []\n",
    "for i in range(len(spacy_comm)):\n",
    "  all_cos_sim_spacy.append(calc_cos_sim_count_vec(all_ft_comm[i], spacy_comm[i])[0][1])\n",
    "\n",
    "sorted(all_cos_sim_spacy, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7953239957993086,\n",
       " 0.784270383288959,\n",
       " 0.7728546233270182,\n",
       " 0.7692639306166029,\n",
       " 0.7603813000949753,\n",
       " 0.7593104742149936,\n",
       " 0.7581093603642679,\n",
       " 0.7537184963392365,\n",
       " 0.749825777576924,\n",
       " 0.7475982045617435,\n",
       " 0.7405160279629593,\n",
       " 0.7391730797696568,\n",
       " 0.7327699869772225,\n",
       " 0.7243865317669208,\n",
       " 0.7227952225480624,\n",
       " 0.7211585276842527,\n",
       " 0.7210127545462429,\n",
       " 0.7193756582020947,\n",
       " 0.7188542025873198,\n",
       " 0.7182557335991091,\n",
       " 0.7175172291598655,\n",
       " 0.705042436618654,\n",
       " 0.704912898855007,\n",
       " 0.7020957136137166,\n",
       " 0.7000223391806029,\n",
       " 0.699979695800079,\n",
       " 0.6937673595094522,\n",
       " 0.6910079483143473,\n",
       " 0.6902610403846762,\n",
       " 0.6843671563031595,\n",
       " 0.6830959423188732,\n",
       " 0.6827604968028924,\n",
       " 0.6824310730523295,\n",
       " 0.6812806487187413,\n",
       " 0.6792623250621805,\n",
       " 0.6737007375350063,\n",
       " 0.6720868312538996,\n",
       " 0.6710502891129948,\n",
       " 0.6705873056132569,\n",
       " 0.6701009371571429,\n",
       " 0.6671667649705758,\n",
       " 0.6663370783926228,\n",
       " 0.6653998750443286,\n",
       " 0.6650983085792687,\n",
       " 0.6650702246545304,\n",
       " 0.6640285896984353,\n",
       " 0.6625617768310097,\n",
       " 0.6622434883226487,\n",
       " 0.6614573608040552,\n",
       " 0.6614081407040487,\n",
       " 0.6611244611837612,\n",
       " 0.659973467853115,\n",
       " 0.6583672524273284,\n",
       " 0.6560381485126154,\n",
       " 0.655449144600024,\n",
       " 0.6549529776254136,\n",
       " 0.6540244608137332,\n",
       " 0.6535283561305564,\n",
       " 0.6513954810954309,\n",
       " 0.6501330374506317,\n",
       " 0.6450518470035216,\n",
       " 0.6444192162659322,\n",
       " 0.6429201428544732,\n",
       " 0.64141354889046,\n",
       " 0.640747364216766,\n",
       " 0.6404951592889088,\n",
       " 0.6393652979286286,\n",
       " 0.6388732921006925,\n",
       " 0.6355414500037637,\n",
       " 0.6346506932666818,\n",
       " 0.6344527842812907,\n",
       " 0.6341604776877066,\n",
       " 0.6340345128105604,\n",
       " 0.6335353199309931,\n",
       " 0.6330756142586784,\n",
       " 0.6327848502189877,\n",
       " 0.6310561354616734,\n",
       " 0.6276818319132095,\n",
       " 0.6275348554101587,\n",
       " 0.6260067736946859,\n",
       " 0.6245482273364094,\n",
       " 0.6243715490232887,\n",
       " 0.6222544972332373,\n",
       " 0.6219538764751725,\n",
       " 0.618957741622482,\n",
       " 0.6162829613927217,\n",
       " 0.6153088585567105,\n",
       " 0.6130697453304731,\n",
       " 0.6122959465543034,\n",
       " 0.6122364474819907,\n",
       " 0.6108260406561586,\n",
       " 0.610157841323127,\n",
       " 0.6082030702875806,\n",
       " 0.6057821362727436,\n",
       " 0.6031336537742019,\n",
       " 0.6014258056020161,\n",
       " 0.6013765247991337,\n",
       " 0.5997171232508886,\n",
       " 0.5974658056485103,\n",
       " 0.5968490404689502,\n",
       " 0.5960038094386629,\n",
       " 0.5955380262790237,\n",
       " 0.5934440008820944,\n",
       " 0.5921967109387654,\n",
       " 0.5915391211562692,\n",
       " 0.5899063303885062,\n",
       " 0.5899040567706688,\n",
       " 0.5844549500249256,\n",
       " 0.5806325623834975,\n",
       " 0.5702605396483993,\n",
       " 0.5686365051097912,\n",
       " 0.5648054021137303,\n",
       " 0.5580593535846445,\n",
       " 0.5535514440440098,\n",
       " 0.5480017072302487,\n",
       " 0.5451812011235035,\n",
       " 0.5369896952597047,\n",
       " 0.5335426067702014,\n",
       " 0.5297263017564297,\n",
       " 0.5173792942677842,\n",
       " 0.5101930872431388,\n",
       " 0.5025517620359816,\n",
       " 0.4716169468045759,\n",
       " 0.4163196881748631]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cos_sim_nltk = []\n",
    "for i in range(len(nltk_comm)):\n",
    "  all_cos_sim_nltk.append(calc_cos_sim_count_vec(all_ft_comm[i], nltk_comm[i])[0][1])\n",
    "\n",
    "sorted(all_cos_sim_nltk, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7805582765133168,\n",
       " 0.7793807007557877,\n",
       " 0.7498346066929102,\n",
       " 0.7350252599077766,\n",
       " 0.733295076872664,\n",
       " 0.7326234187510295,\n",
       " 0.7295254357866824,\n",
       " 0.7244374585272145,\n",
       " 0.7238546752295592,\n",
       " 0.7185062434637455,\n",
       " 0.7173526886292382,\n",
       " 0.7134709309702383,\n",
       " 0.7081025372306506,\n",
       " 0.7004081361290111,\n",
       " 0.694468252978679,\n",
       " 0.6899261258746314,\n",
       " 0.6878663589036689,\n",
       " 0.6849982407218725,\n",
       " 0.6820688790491405,\n",
       " 0.68076699459638,\n",
       " 0.6769297313285413,\n",
       " 0.6757788326841103,\n",
       " 0.6734069132937255,\n",
       " 0.6705653508644213,\n",
       " 0.6697050296231473,\n",
       " 0.6668163087039578,\n",
       " 0.6635484863515022,\n",
       " 0.6624459950154835,\n",
       " 0.6578147491726972,\n",
       " 0.6541013977251863,\n",
       " 0.6535060074474317,\n",
       " 0.652829799344488,\n",
       " 0.6522113450812324,\n",
       " 0.652051893886822,\n",
       " 0.6517222005908682,\n",
       " 0.6507079136417975,\n",
       " 0.6477143003843482,\n",
       " 0.6469318921388305,\n",
       " 0.646493770397001,\n",
       " 0.6442805558018583,\n",
       " 0.6434883239578081,\n",
       " 0.6433552027174023,\n",
       " 0.642617191876622,\n",
       " 0.6419438537773124,\n",
       " 0.6419019997175781,\n",
       " 0.6379386360495407,\n",
       " 0.6377878654091924,\n",
       " 0.6354703911712765,\n",
       " 0.6346309093816951,\n",
       " 0.6300248209318656,\n",
       " 0.6281742283638185,\n",
       " 0.6278398133337124,\n",
       " 0.6260649181662576,\n",
       " 0.6243342159048492,\n",
       " 0.6242301256886671,\n",
       " 0.6216814858648188,\n",
       " 0.6199375926257195,\n",
       " 0.6194114448865824,\n",
       " 0.6189618791842378,\n",
       " 0.6188552536161214,\n",
       " 0.6186524786082355,\n",
       " 0.618217958741268,\n",
       " 0.618028448153296,\n",
       " 0.6167229112516287,\n",
       " 0.6116862316377848,\n",
       " 0.6080298607926425,\n",
       " 0.6075605013451013,\n",
       " 0.6057674509639824,\n",
       " 0.6044138797865526,\n",
       " 0.6042150550421583,\n",
       " 0.6039256648496042,\n",
       " 0.6022109855009367,\n",
       " 0.6021664533119604,\n",
       " 0.5982338218818624,\n",
       " 0.5981066083945484,\n",
       " 0.5971695067448688,\n",
       " 0.5971637485175134,\n",
       " 0.597105047019648,\n",
       " 0.5958767701011115,\n",
       " 0.5933221305484205,\n",
       " 0.5916846666941428,\n",
       " 0.591001309677671,\n",
       " 0.5908832316198028,\n",
       " 0.5900959231106175,\n",
       " 0.5883884700505739,\n",
       " 0.5863733659392011,\n",
       " 0.5862542401114477,\n",
       " 0.5860484855015258,\n",
       " 0.5837985255276165,\n",
       " 0.5837725698098414,\n",
       " 0.5763777152834911,\n",
       " 0.571305574771378,\n",
       " 0.5637508630053489,\n",
       " 0.5616940298369865,\n",
       " 0.5596622070423835,\n",
       " 0.5573711251754303,\n",
       " 0.5571112316136962,\n",
       " 0.5502818940626638,\n",
       " 0.5448765841587564,\n",
       " 0.5402175601985518,\n",
       " 0.5356929370045399,\n",
       " 0.5316352491552594,\n",
       " 0.5312898020543462,\n",
       " 0.528505382494509,\n",
       " 0.5225879971845396,\n",
       " 0.5217529355447349,\n",
       " 0.5216688990081642,\n",
       " 0.5197207251451915,\n",
       " 0.5175609581103662,\n",
       " 0.5141319567068752,\n",
       " 0.5128480263627918,\n",
       " 0.5110602531034132,\n",
       " 0.5091774083246382,\n",
       " 0.5050843498601558,\n",
       " 0.49554452022589257,\n",
       " 0.4938505590380836,\n",
       " 0.49369475432076365,\n",
       " 0.49101750033068164,\n",
       " 0.4825690796320455,\n",
       " 0.4813894891808373,\n",
       " 0.47306900825450654,\n",
       " 0.46851379496882195,\n",
       " 0.4591496237404173,\n",
       " 0.44474866611331426]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cos_sim_gpt = []\n",
    "for i in range(len(gpt_comm)):\n",
    "  all_cos_sim_gpt.append(calc_cos_sim_count_vec(all_ft_comm[i], gpt_comm[i])[0][1])\n",
    "\n",
    "sorted(all_cos_sim_gpt, reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('anly521')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "045993bec6224f6bf157e7265b027fdb84d23efb85222067a0580c561b3b8fe4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
